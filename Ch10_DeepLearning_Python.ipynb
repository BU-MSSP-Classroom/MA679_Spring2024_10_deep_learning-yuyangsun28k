{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc378879",
   "metadata": {},
   "source": [
    "# Class Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117",
   "metadata": {},
   "source": [
    "## In class activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b9c178",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib.pyplot import subplots\n",
    "#import statsmodels.api as sm\n",
    "from plotnine import *\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as sm\n",
    "#import ISLP as islp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8f84d",
   "metadata": {},
   "source": [
    "### Ames Housing data\n",
    "\n",
    "\n",
    "Please take a look at the Ames Hoursing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7792c845",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde9d19",
   "metadata": {},
   "source": [
    "Use data of `ames_raw` up to 2008 predict the housing price for the later years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb9eca2",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da715eb",
   "metadata": {},
   "source": [
    "Use the following loss function calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145b46d4",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_loss(prediction,actual):\n",
    "  difpred = actual-prediction\n",
    "  RMSE =pow(difpred.pow(2).mean(),1/2)\n",
    "  operation_loss=abs(sum(difpred[difpred<0]))+sum(0.1*actual[difpred>0])\n",
    "  return RMSE,operation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124297b",
   "metadata": {},
   "source": [
    "Use a simple neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1cd4b1f",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE,echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: nan\n",
      "Epoch 2, Loss: nan\n",
      "Epoch 3, Loss: nan\n",
      "Epoch 4, Loss: nan\n",
      "Epoch 5, Loss: nan\n",
      "Epoch 6, Loss: nan\n",
      "Epoch 7, Loss: nan\n",
      "Epoch 8, Loss: nan\n",
      "Epoch 9, Loss: nan\n",
      "Epoch 10, Loss: nan\n",
      "Epoch 11, Loss: nan\n",
      "Epoch 12, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[1;32m     66\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 67\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     70\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming ames_raw_2008 is correctly loaded and prepared\n",
    "X = ames_raw_2008.drop('SalePrice', axis=1)\n",
    "y = ames_raw_2008['SalePrice']\n",
    "\n",
    "# One-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating DataLoader instances\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "model = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        test_predictions = model(X_batch)\n",
    "        test_loss = criterion(test_predictions, y_batch)\n",
    "        total_test_loss += test_loss.item()\n",
    "\n",
    "average_test_loss = total_test_loss / len(test_loader)\n",
    "print(f'Test MSE: {average_test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90018571",
   "metadata": {},
   "source": [
    "When you decide on your model use the following to come up with your test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0e341",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE,echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pred_2009=# Predict using ames_raw_2009\n",
    "calc_loss(pred_2009,ames_raw_2009.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d1e7",
   "metadata": {},
   "source": [
    "Try to answer the following additional questions.\n",
    "\n",
    "- Does your model indicate a good fit?\n",
    "\n",
    "\n",
    "- How does your model result compare to the previous models you fit?\n",
    "\n",
    "\n",
    "- Can you explain what feature was important determinant of the price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9dd0",
   "metadata": {},
   "source": [
    "### COVID 19 Survival in Mexico\n",
    "\n",
    "Let's revisit COVID-19 in Mexico dataset from the [Mexican government](https://datos.gob.mx/busca/dataset/informacion-referente-a-casos-covid-19-en-mexico).  This data is a version downloaded from [Kaggle](https://www.kaggle.com/datasets/meirnizri/covid19-dataset?resource=download).  The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "- sex: 1 for female and 2 for male.\n",
    "- age: of the patient.\n",
    "- classification: COVID test findings. Values 1-3 mean that the patient was diagnosed with COVID in different degrees. 4 or higher means that the patient is not a carrier of COVID or that the test is inconclusive.\n",
    "- patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "- pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "- pregnancy: whether the patient is pregnant or not.\n",
    "- diabetes: whether the patient has diabetes or not.\n",
    "- copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "- asthma: whether the patient has asthma or not.\n",
    "- inmsupr: whether the patient is immunosuppressed or not.\n",
    "- hypertension: whether the patient has hypertension or not.\n",
    "- cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "- renal chronic: whether the patient has chronic renal disease or not.\n",
    "- other disease: whether the patient has other disease or not.\n",
    "- obesity: whether the patient is obese or not.\n",
    "- tobacco: whether the patient is a tobacco user.\n",
    "- usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "- medical unit: type of institution of the National Health System that provided the care.\n",
    "- intubed: whether the patient was connected to the ventilator.\n",
    "- icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "- date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef41dc",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "Train_COVID= pd.read_csv('Train_COVID.zip',compression='zip')\n",
    "Test_COVID= pd.read_csv('Test_COVID.zip',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9846d1",
   "metadata": {},
   "source": [
    "- Fit a sequence model that predicts the number of cases a week a head.\n",
    "\n",
    "- Modify your model to make prediction for different gender.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2ddbc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63065e78",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db356786",
   "metadata": {},
   "source": [
    "## Problem set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2c5a9",
   "metadata": {},
   "source": [
    "### Writing your own gradient decent\n",
    "\n",
    "Consider the simple function $R(\\beta) = sin(\\beta) + \\beta/10$.\n",
    "\n",
    "(a) Draw a graph of this function over the range $\\beta \\in [−6, 6]$.\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683d706",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788e2b3",
   "metadata": {},
   "source": [
    "(b) What is the derivative of this function?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6932c",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c379",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(c) Given $\\beta_0 = 2.3$, run gradient descent to find a local minimum of $R(\\beat)$ using a learning rate of $\\rho= 0.1$. Show each of $\\beta_0,\\beta_1,\\dots$ in your plot, as well as the final answer.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9f93f",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134f645",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(d) Repeat with $\\beta_0 = 1.4$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efea5a0",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b33b24",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f6ae",
   "metadata": {},
   "source": [
    "### Default\n",
    "\n",
    "Fit a neural network to the Default data. Use a single hidden layer with 10 units, and dropout regularization. Have a look at Labs 10.9.1–10.9.2 for guidance. Compare the classification performance of your model with that of linear logistic regression.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15d9d3",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb5727",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d06410",
   "metadata": {},
   "source": [
    "### IMDb\n",
    "\n",
    "Repeat the analysis of Lab 10.9.5 on the IMDb data using a similarly structured neural network. We used 16 hidden units at each of two hidden layers. Explore the effect of increasing this to 32 and 64 units per layer, with and without 30% dropout regularization.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d63690",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b61f2",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e719c",
   "metadata": {},
   "source": [
    "### NYSE\n",
    "\n",
    "Fit a lag-5 autoregressive model to the NYSE data, as described in the text and Lab 10.9.6. Refit the model with a 12-level factor representing the month. Does this factor improve the performance of the model?\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537a6d2",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82790743",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79190c",
   "metadata": {},
   "source": [
    "### NYSE 2\n",
    "In Section 10.9.6, we showed how to fit a linear AR model to the\n",
    "NYSE data using the `LinearRegression()` function. However, we also\n",
    "mentioned that we can “flatten” the short sequences produced for\n",
    "the RNN model in order to fit a linear AR model. Use this latter\n",
    "approach to fit a linear AR model to the NYSE data. Compare the test\n",
    "R2 of this linear AR model to that of the linear AR model that we fit\n",
    "in the lab. What are the advantages/disadvantages of each approach?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b49f2e",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f42d",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "Repeat the previous exercise, but now fit a nonlinear AR model by\n",
    "“flattening” the short sequences produced for the RNN model.\n",
    "\n",
    " Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a120",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5e731",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aaf64",
   "metadata": {},
   "source": [
    "### NYSE 3\n",
    "\n",
    "Consider the RNN fit to the NYSE data in Section 10.9.6. Modify the code to allow inclusion of the variable day_of_week, and fit the RNN. Compute the test $R^2$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d3d82",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce0591",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647a4b",
   "metadata": {},
   "source": [
    "### CNN on photo\n",
    "\n",
    "From your collection of personal photographs, pick 10 images of animals\n",
    "(such as dogs, cats, birds, farm animals, etc.). If the subject\n",
    "does not occupy a reasonable part of the image, then crop the image.\n",
    "Now use a pretrained image classification CNN as in Lab 10.9.4 to\n",
    "predict the class of each of your images, and report the probabilities\n",
    "for the top five predicted classes for each image.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81612",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56a27",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Your Name",
   "date": "2022-12-21",
   "output": "github_document",
   "title": "Deep Learning"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ],
    [
     "css",
     "css",
     "",
     ""
    ],
    [
     "Python3",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
